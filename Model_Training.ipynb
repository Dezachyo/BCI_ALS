{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a019fb8-c924-4d04-b3de-c681a8f5680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easygui import *\n",
    "import pyxdf\n",
    "import PyQt5\n",
    "import mne\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import mne\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#from joblib import dump,load\n",
    "import pickle\n",
    "# For interactive plots\n",
    "from IPython import get_ipython\n",
    "get_ipython().run_line_magic('matplotlib', 'qt')\n",
    "#from subfunctions import *\n",
    "\n",
    "\n",
    "from mne.decoding import (SlidingEstimator, GeneralizingEstimator, Scaler,\n",
    "                          cross_val_multiscore, LinearModel, get_coef,\n",
    "                          Vectorizer, CSP)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os,numpy as np,pandas as pd\n",
    "from collections import OrderedDict\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# MNE functions\n",
    "from mne import Epochs,find_events\n",
    "from mne.decoding import Vectorizer\n",
    "\n",
    "\n",
    "# Scikit-learn and Pyriemann ML functionalities\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import cross_val_score, StratifiedShuffleSplit\n",
    "from pyriemann.estimation import ERPCovariances, XdawnCovariances, Xdawn\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from pyriemann.classification import MDM\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aad3e31-8ee9-4f96-b6f0-ad23a7aa9074",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BandwidthFilter:\n",
    "    def __init__(self, l_freq, h_freq, method):\n",
    "        self.l_freq = l_freq\n",
    "        self.h_freq = h_freq\n",
    "        self.method = method\n",
    "        \n",
    "class model:\n",
    "    def __init__(self, clsf, input_shape, ch_names,bandwidthfilter):\n",
    "        self.clsf = clsf\n",
    "        self.input_shape = input_shape\n",
    "        self.ch_names = ch_names\n",
    "        self.bandwidthfilter = bandwidthfilter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7278a30-e79a-470c-9712-66d4453fc563",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_file_name = 'Omri_Recording_001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9e5d1bb-1bdd-46e5-bc38-aa2f70ac760c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading c:\\Users\\user\\Documents\\BCI_ALS\\BCI_ALS\\Data\\Processed Data\\Omri_Recording_001_Processed ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     496.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "277 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "current_path = pathlib.Path().absolute()  \n",
    "data_fname = current_path /'Data'/'Processed Data'/ (processed_file_name + '_Processed')\n",
    "epochs = mne.read_epochs(data_fname)\n",
    "\n",
    "#read the pickle file\n",
    "picklefile = open(current_path /'Data'/'Processed Data'/ (processed_file_name+'_Filter'), 'rb')\n",
    "#unpickle the dataframe\n",
    "bandwidth_filter = pickle.load(picklefile)\n",
    "#close file\n",
    "picklefile.close()\n",
    "\n",
    "#bandwidth_filter = load(current_path /'Data'/'Processed Data'/ (processed_file_name+'_Filter'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f9b7bcf-359c-4c88-a9b8-49fdb5f91d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = epochs.get_data()  # MEG signals: n_epochs, n_meg_channels, n_times\n",
    "# Remove baslineperiod\n",
    "baseline_duration = -0.2\n",
    "onset_sample = int(np.absolute(baseline_duration) * 125)\n",
    "X = X[:,:,onset_sample::]\n",
    "\n",
    "y = epochs.events[:, 2]  # target: auditory left vs visual left\n",
    "y = y-1 # 0's and 1's instead of 1's and 2's\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80e2c0d0-b7fa-46dd-873d-fc9630cc7cfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\pyriemann\\tangentspace.py\", line 200, in fit_transform\n    self.reference_ = mean_covariance(\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\pyriemann\\utils\\mean.py\", line 591, in mean_covariance\n    C = mean_methods[metric](covmats, sample_weight=sample_weight, *args)\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\pyriemann\\utils\\mean.py\", line 457, in mean_riemann\n    J = np.einsum('a,abc->bc', sample_weight, logm(Cm12 @ covmats @ Cm12))\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\pyriemann\\utils\\base.py\", line 71, in logm\n    return _matrix_operator(C, np.log)\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\pyriemann\\utils\\base.py\", line 14, in _matrix_operator\n    raise ValueError(\nValueError: Matrices must be positive definite. Add regularization to avoid this error.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m methods \u001b[39m=\u001b[39m []\n\u001b[0;32m     31\u001b[0m \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m clfs:\n\u001b[1;32m---> 32\u001b[0m     res \u001b[39m=\u001b[39m cross_val_score(clfs[m], X, y\u001b[39m==\u001b[39;49m\u001b[39m1\u001b[39;49m, scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mroc_auc\u001b[39;49m\u001b[39m'\u001b[39;49m, cv\u001b[39m=\u001b[39;49mcv, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     33\u001b[0m     auc\u001b[39m.\u001b[39mextend(res)\n\u001b[0;32m     34\u001b[0m     methods\u001b[39m.\u001b[39mextend([m]\u001b[39m*\u001b[39m\u001b[39mlen\u001b[39m(res))\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    527\u001b[0m )\n\u001b[0;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:285\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m    266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m cv\u001b[39m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[1;32m--> 285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(scoring):\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\pyriemann\\tangentspace.py\", line 200, in fit_transform\n    self.reference_ = mean_covariance(\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\pyriemann\\utils\\mean.py\", line 591, in mean_covariance\n    C = mean_methods[metric](covmats, sample_weight=sample_weight, *args)\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\pyriemann\\utils\\mean.py\", line 457, in mean_riemann\n    J = np.einsum('a,abc->bc', sample_weight, logm(Cm12 @ covmats @ Cm12))\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\pyriemann\\utils\\base.py\", line 71, in logm\n    return _matrix_operator(C, np.log)\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\pyriemann\\utils\\base.py\", line 14, in _matrix_operator\n    raise ValueError(\nValueError: Matrices must be positive definite. Add regularization to avoid this error.\n"
     ]
    }
   ],
   "source": [
    "clfs = OrderedDict()\n",
    "clfs['Vect + LR'] = make_pipeline(Vectorizer(), StandardScaler(), LogisticRegression())\n",
    "clfs['Vect + RegLDA'] = make_pipeline(Vectorizer(), LDA(shrinkage='auto', solver='eigen'))\n",
    "clfs['Xdawn + RegLDA'] = make_pipeline(Xdawn(2, classes=[1]), Vectorizer(), LDA(shrinkage='auto', solver='eigen'))\n",
    "\n",
    "clfs['XdawnCov + TS'] = make_pipeline(XdawnCovariances(estimator='oas'), TangentSpace(), LogisticRegression())\n",
    "clfs['XdawnCov + MDM'] = make_pipeline(XdawnCovariances(estimator='oas'), MDM())\n",
    "\n",
    "\n",
    "clfs['ERPCov + TS'] = make_pipeline(ERPCovariances(), TangentSpace(), LogisticRegression())\n",
    "clfs['ERPCov + MDM'] = make_pipeline(ERPCovariances(), MDM())\n",
    "\n",
    "\n",
    "# format data\n",
    "epochs.pick_types(eeg=True)\n",
    "X = epochs.get_data() * 1e6\n",
    "baseline_duration = -0.2\n",
    "onset_sample = int(np.absolute(baseline_duration) * 125)\n",
    "X = X[:,:,onset_sample::]\n",
    "\n",
    "times = epochs.times\n",
    "y = epochs.events[:, -1]\n",
    "y = y-1\n",
    "\n",
    "# define cross validation\n",
    "cv = StratifiedShuffleSplit(n_splits=10, test_size=0.25, random_state=42)\n",
    "\n",
    "# run cross validation for each pipeline\n",
    "auc = []\n",
    "methods = []\n",
    "for m in clfs:\n",
    "    res = cross_val_score(clfs[m], X, y==1, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "    auc.extend(res)\n",
    "    methods.extend([m]*len(res))\n",
    "\n",
    "results = pd.DataFrame(data=auc, columns=['AUC'])\n",
    "results['Method'] = methods\n",
    "\n",
    "plt.figure(figsize=[8,4])\n",
    "sns.barplot(data=results, x='AUC', y='Method')\n",
    "plt.xlim(0.2, 0.85)\n",
    "sns.despine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0496e062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fff989-e3f9-442e-b4bc-e599a1055c34",
   "metadata": {},
   "source": [
    "## Lets fit the model to the data and save it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff5087c-183c-4f8b-aaa4-f5681fe3000c",
   "metadata": {},
   "source": [
    "### First, Choose the best model to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d649c447-9fdb-4125-a35a-ff14228b18da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = clfs['Vect + LR'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "94ebd4d1-0bb6-4ee7-8df3-67fb1ef066c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X,y)\n",
    "input_shape = X.shape\n",
    "ch_names = epochs.ch_names\n",
    "\n",
    "\n",
    "m = model(pipe,input_shape,ch_names,bandwidth_filter)\n",
    "\n",
    "\n",
    "fname = processed_file_name+'_model'\n",
    "path_fname = current_path /'Models'/ fname\n",
    "\n",
    "\n",
    "#create a pickle file\n",
    "picklefile = open(path_fname, 'wb')\n",
    "#pickle the dictionary and write it to file\n",
    "pickle.dump(m, picklefile)\n",
    "#close the file\n",
    "picklefile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f9a3d6e0-76f7-4b8c-bca9-808515041fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the pickle file\n",
    "picklefile = open(path_fname, 'rb')\n",
    "#unpickle the dataframe\n",
    "loaded = pickle.load(picklefile)\n",
    "#close file\n",
    "picklefile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e751379-f1e7-4d02-84f8-17222f6dd433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6383aa94-ad17-4111-976c-10bee868be60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
