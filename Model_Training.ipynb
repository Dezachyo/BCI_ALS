{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a019fb8-c924-4d04-b3de-c681a8f5680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easygui import *\n",
    "import PyQt5\n",
    "import mne\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import mne\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#from joblib import dump,load\n",
    "import pickle\n",
    "# For interactive plots\n",
    "from IPython import get_ipython\n",
    "get_ipython().run_line_magic('matplotlib', 'qt')\n",
    "#from subfunctions import *\n",
    "\n",
    "\n",
    "from mne.decoding import (SlidingEstimator, GeneralizingEstimator, Scaler,\n",
    "                          cross_val_multiscore, LinearModel, get_coef,\n",
    "                          Vectorizer, CSP)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os,numpy as np,pandas as pd\n",
    "from collections import OrderedDict\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# MNE functions\n",
    "from mne import Epochs,find_events\n",
    "from mne.decoding import Vectorizer\n",
    "\n",
    "\n",
    "# Scikit-learn and Pyriemann ML functionalities\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import cross_val_score, StratifiedShuffleSplit\n",
    "from pyriemann.estimation import ERPCovariances, XdawnCovariances, Xdawn\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from pyriemann.classification import MDM\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aad3e31-8ee9-4f96-b6f0-ad23a7aa9074",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BandwidthFilter:\n",
    "    def __init__(self, l_freq, h_freq, method):\n",
    "        self.l_freq = l_freq\n",
    "        self.h_freq = h_freq\n",
    "        self.method = method\n",
    "        \n",
    "class model:\n",
    "    def __init__(self, clsf, input_shape, ch_names,bandwidthfilter):\n",
    "        self.clsf = clsf\n",
    "        self.input_shape = input_shape\n",
    "        self.ch_names = ch_names\n",
    "        self.bandwidthfilter = bandwidthfilter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7278a30-e79a-470c-9712-66d4453fc563",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_file_name = 'Omri_Recording_001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9e5d1bb-1bdd-46e5-bc38-aa2f70ac760c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading c:\\Users\\user\\Documents\\BCI_ALS\\BCI_ALS\\Data\\Processed Data\\Omri_Recording_001_Processed ...\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     496.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "277 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "current_path = pathlib.Path().absolute()  \n",
    "data_fname = current_path /'Data'/'Processed Data'/ (processed_file_name + '_Processed')\n",
    "epochs = mne.read_epochs(data_fname)\n",
    "\n",
    "#read the pickle file\n",
    "picklefile = open(current_path /'Data'/'Processed Data'/ (processed_file_name+'_Filter'), 'rb')\n",
    "#unpickle the dataframe\n",
    "bandwidth_filter = pickle.load(picklefile)\n",
    "#close file\n",
    "picklefile.close()\n",
    "\n",
    "#bandwidth_filter = load(current_path /'Data'/'Processed Data'/ (processed_file_name+'_Filter'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f9b7bcf-359c-4c88-a9b8-49fdb5f91d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = epochs.get_data()  # MEG signals: n_epochs, n_meg_channels, n_times\n",
    "# Remove baslineperiod\n",
    "baseline_duration = -0.2\n",
    "onset_sample = int(np.absolute(baseline_duration) * 125)\n",
    "X = X[:,:,onset_sample::]\n",
    "\n",
    "y = epochs.events[:, 2]  # target: auditory left vs visual left\n",
    "y = y-1 # 0's and 1's instead of 1's and 2's\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80e2c0d0-b7fa-46dd-873d-fc9630cc7cfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\pyriemann\\tangentspace.py\", line 200, in fit_transform\n    self.reference_ = mean_covariance(\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\pyriemann\\utils\\mean.py\", line 591, in mean_covariance\n    C = mean_methods[metric](covmats, sample_weight=sample_weight, *args)\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\pyriemann\\utils\\mean.py\", line 457, in mean_riemann\n    J = np.einsum('a,abc->bc', sample_weight, logm(Cm12 @ covmats @ Cm12))\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\pyriemann\\utils\\base.py\", line 71, in logm\n    return _matrix_operator(C, np.log)\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\pyriemann\\utils\\base.py\", line 14, in _matrix_operator\n    raise ValueError(\nValueError: Matrices must be positive definite. Add regularization to avoid this error.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16512\\419338848.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mmethods\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclfs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclfs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'balanced_accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[0mauc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mmethods\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m     cv_results = cross_validate(\n\u001b[0m\u001b[0;32m    516\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    283\u001b[0m     )\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m     \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m     \u001b[1;31m# For callabe scoring, the return type is only know after calling. If the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    365\u001b[0m                 \u001b[1;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m             )\n\u001b[1;32m--> 367\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\pyriemann\\tangentspace.py\", line 200, in fit_transform\n    self.reference_ = mean_covariance(\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\pyriemann\\utils\\mean.py\", line 591, in mean_covariance\n    C = mean_methods[metric](covmats, sample_weight=sample_weight, *args)\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\pyriemann\\utils\\mean.py\", line 457, in mean_riemann\n    J = np.einsum('a,abc->bc', sample_weight, logm(Cm12 @ covmats @ Cm12))\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\pyriemann\\utils\\base.py\", line 71, in logm\n    return _matrix_operator(C, np.log)\n  File \"c:\\Users\\user\\anaconda3\\envs\\BCI-ALS\\lib\\site-packages\\pyriemann\\utils\\base.py\", line 14, in _matrix_operator\n    raise ValueError(\nValueError: Matrices must be positive definite. Add regularization to avoid this error.\n"
     ]
    }
   ],
   "source": [
    "clfs = OrderedDict()\n",
    "clfs['Vect + LR'] = make_pipeline(Vectorizer(), StandardScaler(), LogisticRegression())\n",
    "clfs['Vect + RegLDA'] = make_pipeline(Vectorizer(), LDA(shrinkage='auto', solver='eigen'))\n",
    "clfs['Xdawn + RegLDA'] = make_pipeline(Xdawn(2, classes=[1]), Vectorizer(), LDA(shrinkage='auto', solver='eigen'))\n",
    "\n",
    "clfs['XdawnCov + TS'] = make_pipeline(XdawnCovariances(estimator='oas'), TangentSpace(), LogisticRegression())\n",
    "clfs['XdawnCov + MDM'] = make_pipeline(XdawnCovariances(estimator='oas'), MDM())\n",
    "\n",
    "\n",
    "clfs['ERPCov + TS'] = make_pipeline(ERPCovariances(), TangentSpace(), LogisticRegression())\n",
    "clfs['ERPCov + MDM'] = make_pipeline(ERPCovariances(), MDM())\n",
    "\n",
    "\n",
    "# format data\n",
    "epochs.pick_types(eeg=True)\n",
    "X = epochs.get_data() * 1e6\n",
    "baseline_duration = -0.2\n",
    "onset_sample = int(np.absolute(baseline_duration) * 125)\n",
    "X = X[:,:,onset_sample::]\n",
    "\n",
    "times = epochs.times\n",
    "y = epochs.events[:, -1]\n",
    "y = y-1\n",
    "\n",
    "# define cross validation\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.20, random_state=39)\n",
    "\n",
    "# run cross validation for each pipeline\n",
    "auc = []\n",
    "methods = []\n",
    "for m in clfs:\n",
    "    res = cross_val_score(clfs[m], X, y==1, scoring='balanced_accuracy', cv=cv, n_jobs=-1)\n",
    "    auc.extend(res)\n",
    "    methods.extend([m]*len(res))\n",
    "\n",
    "results = pd.DataFrame(data=auc, columns=['AUC'])\n",
    "results['Method'] = methods\n",
    "\n",
    "plt.figure(figsize=[8,4])\n",
    "sns.barplot(data=results, x='AUC', y='Method')\n",
    "plt.xlim(0.2, 0.85)\n",
    "sns.despine()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fff989-e3f9-442e-b4bc-e599a1055c34",
   "metadata": {},
   "source": [
    "## Lets fit the model to the data and save it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff5087c-183c-4f8b-aaa4-f5681fe3000c",
   "metadata": {},
   "source": [
    "### First, Choose the best model to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d649c447-9fdb-4125-a35a-ff14228b18da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = clfs['Vect + LR'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "94ebd4d1-0bb6-4ee7-8df3-67fb1ef066c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X,y)\n",
    "input_shape = X.shape\n",
    "ch_names = epochs.ch_names\n",
    "\n",
    "\n",
    "m = model(pipe,input_shape,ch_names,bandwidth_filter)\n",
    "\n",
    "\n",
    "fname = processed_file_name+'_model'\n",
    "path_fname = current_path /'Models'/ fname\n",
    "\n",
    "\n",
    "#create a pickle file\n",
    "picklefile = open(path_fname, 'wb')\n",
    "#pickle the dictionary and write it to file\n",
    "pickle.dump(m, picklefile)\n",
    "#close the file\n",
    "picklefile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f9a3d6e0-76f7-4b8c-bca9-808515041fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the pickle file\n",
    "picklefile = open(path_fname, 'rb')\n",
    "#unpickle the dataframe\n",
    "loaded = pickle.load(picklefile)\n",
    "#close file\n",
    "picklefile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e751379-f1e7-4d02-84f8-17222f6dd433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6383aa94-ad17-4111-976c-10bee868be60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
